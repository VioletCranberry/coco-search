---
phase: 32-full-language-coverage-documentation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/cocosearch/management/stats.py
  - src/cocosearch/cli.py
autonomous: true

must_haves:
  truths:
    - "User can run 'cocosearch stats <index>' to see per-language breakdown"
    - "Stats table shows Language, Files, Chunks, Lines columns"
    - "Total row sums all languages at bottom of table"
    - "JSON output includes per-language statistics via '--json' flag"
    - "Pre-v1.7 indexes show N/A for line count (graceful degradation)"
  artifacts:
    - path: "src/cocosearch/management/stats.py"
      provides: "get_language_stats function for per-language aggregation"
      contains: "def get_language_stats"
    - path: "src/cocosearch/cli.py"
      provides: "Updated stats_command with per-language table"
      contains: "get_language_stats"
  key_links:
    - from: "src/cocosearch/cli.py"
      to: "get_language_stats"
      via: "import from management.stats"
      pattern: "from cocosearch.management.*import.*get_language_stats"
    - from: "src/cocosearch/management/stats.py"
      to: "database"
      via: "SQL GROUP BY language_id"
      pattern: "GROUP BY.*language"
---

<objective>
Add per-language statistics to `cocosearch stats` command showing files, chunks, and lines per language.

Purpose: Give users visibility into codebase composition by language.
Output: Enhanced stats command with per-language breakdown table and total row.
</objective>

<execution_context>
@/Users/fedorzhdanov/.claude/get-shit-done/workflows/execute-plan.md
@/Users/fedorzhdanov/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/32-full-language-coverage-documentation/32-RESEARCH.md
@src/cocosearch/management/stats.py
@src/cocosearch/cli.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add get_language_stats function</name>
  <files>src/cocosearch/management/stats.py</files>
  <action>
Add new function `get_language_stats` that returns per-language statistics using SQL GROUP BY.

```python
def get_language_stats(index_name: str) -> list[dict]:
    """Get per-language statistics for an index.

    Uses SQL GROUP BY for efficient aggregation at database level.
    Gracefully handles pre-v1.7 indexes that lack content_text column.

    Args:
        index_name: The name of the index.

    Returns:
        List of dicts with keys:
        - language: Language identifier (e.g., "python", "hcl")
        - file_count: Number of unique files for this language
        - chunk_count: Number of chunks for this language
        - line_count: Number of lines (None if pre-v1.7 index)

        List is sorted by chunk_count descending.

    Raises:
        ValueError: If the index does not exist.
    """
    pool = get_connection_pool()
    table_name = get_table_name(index_name)

    # First verify the table exists
    check_query = """
        SELECT EXISTS (
            SELECT 1 FROM information_schema.tables
            WHERE table_schema = 'public'
              AND table_name = %s
        )
    """

    with pool.connection() as conn:
        with conn.cursor() as cur:
            cur.execute(check_query, (table_name,))
            (exists,) = cur.fetchone()

            if not exists:
                raise ValueError(f"Index '{index_name}' not found")

            # Check if content_text column exists (v1.7+)
            col_check = """
                SELECT column_name FROM information_schema.columns
                WHERE table_name = %s AND column_name = 'content_text'
            """
            cur.execute(col_check, (table_name,))
            has_content_text = cur.fetchone() is not None

            # Build query with conditional line count
            if has_content_text:
                stats_query = f"""
                    SELECT
                        COALESCE(language_id, 'unknown') as language,
                        COUNT(DISTINCT filename) as file_count,
                        COUNT(*) as chunk_count,
                        SUM(array_length(string_to_array(content_text, E'\\n'), 1)) as line_count
                    FROM {table_name}
                    GROUP BY language_id
                    ORDER BY chunk_count DESC
                """
            else:
                # Graceful degradation for pre-v1.7 indexes
                stats_query = f"""
                    SELECT
                        COALESCE(language_id, 'unknown') as language,
                        COUNT(DISTINCT filename) as file_count,
                        COUNT(*) as chunk_count,
                        NULL as line_count
                    FROM {table_name}
                    GROUP BY language_id
                    ORDER BY chunk_count DESC
                """

            cur.execute(stats_query)
            rows = cur.fetchall()

            return [
                {
                    "language": row[0] if row[0] else "unknown",
                    "file_count": row[1],
                    "chunk_count": row[2],
                    "line_count": row[3],
                }
                for row in rows
            ]
```

Update the module's imports to ensure get_connection_pool and get_table_name are available (they already are).

Also update the management/__init__.py to export the new function:
Add `get_language_stats` to the exports if there's an __all__ list, or add the import.
  </action>
  <verify>
Run: `python -c "from cocosearch.management.stats import get_language_stats; print('OK')"`
Expected: "OK" with no import errors
  </verify>
  <done>get_language_stats function exists and returns per-language statistics with SQL aggregation</done>
</task>

<task type="auto">
  <name>Task 2: Update stats CLI for per-language display</name>
  <files>src/cocosearch/cli.py, src/cocosearch/management/__init__.py</files>
  <action>
Update stats_command to show per-language breakdown when viewing a specific index.

1. Update import in cli.py to include get_language_stats:
```python
from cocosearch.management import clear_index, derive_index_from_git, get_stats, get_language_stats, list_indexes
```

2. Update management/__init__.py to export get_language_stats:
```python
from cocosearch.management.stats import format_bytes, get_stats, get_language_stats
```

3. Modify stats_command to show per-language breakdown:

Replace the single-index section (the `if args.index:` branch) with enhanced version:

```python
if args.index:
    # Stats for specific index
    try:
        stats = get_stats(args.index)
        stats["name"] = args.index
        lang_stats = get_language_stats(args.index)
    except ValueError as e:
        if args.pretty:
            console.print(f"[bold red]Error:[/bold red] {e}")
        else:
            print(json.dumps({"error": str(e)}))
        return 1

    if args.pretty:
        from rich.table import Table

        # Summary stats first
        console.print(f"\n[bold]Index:[/bold] {args.index}")
        console.print(f"[dim]Files: {stats['file_count']} | Chunks: {stats['chunk_count']} | Size: {stats['storage_size_pretty']}[/dim]\n")

        # Per-language breakdown table
        table = Table(title="Language Statistics")
        table.add_column("Language", style="cyan", no_wrap=True)
        table.add_column("Files", justify="right")
        table.add_column("Chunks", justify="right")
        table.add_column("Lines", justify="right")

        total_files = 0
        total_chunks = 0
        total_lines = 0
        has_line_counts = any(ls["line_count"] is not None for ls in lang_stats)

        for ls in lang_stats:
            line_str = f"{ls['line_count']:,}" if ls["line_count"] is not None else "N/A"
            table.add_row(
                ls["language"],
                str(ls["file_count"]),
                str(ls["chunk_count"]),
                line_str,
            )
            total_files += ls["file_count"]
            total_chunks += ls["chunk_count"]
            if ls["line_count"] is not None:
                total_lines += ls["line_count"]

        # Add totals row
        table.add_section()
        total_lines_str = f"{total_lines:,}" if has_line_counts else "N/A"
        table.add_row("TOTAL", str(total_files), str(total_chunks), total_lines_str, style="bold")

        console.print(table)

        if not has_line_counts:
            console.print("\n[dim]Note: Line counts require v1.7+ index. Re-index to enable.[/dim]")
    else:
        # JSON output includes both summary and per-language stats
        output = {
            **stats,
            "languages": lang_stats,
        }
        print(json.dumps(output, indent=2))
```
  </action>
  <verify>
Run: `uv run cocosearch stats <existing_index> --pretty`
Expected: Shows summary line + per-language table with Language, Files, Chunks, Lines columns and TOTAL row

Run: `uv run cocosearch stats <existing_index> --json | python -c "import sys,json; d=json.load(sys.stdin); print('languages' in d)"`
Expected: "True"
  </verify>
  <done>
- `cocosearch stats <index> --pretty` shows per-language breakdown table
- Table has Language, Files, Chunks, Lines columns
- TOTAL row at bottom sums all languages
- JSON output includes "languages" array with per-language stats
- Pre-v1.7 indexes show "N/A" for line counts
  </done>
</task>

</tasks>

<verification>
1. `uv run cocosearch stats <index> --pretty` shows per-language table
2. Table includes TOTAL row with sums
3. `uv run cocosearch stats <index> --json` includes "languages" key with array
4. No crashes or import errors
5. Existing stats behavior for all indexes (`cocosearch stats`) still works
</verification>

<success_criteria>
- get_language_stats function implemented with SQL GROUP BY
- stats command shows per-language breakdown for specific index
- JSON output includes languages array
- Graceful degradation for pre-v1.7 indexes (N/A for lines)
- All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/32-full-language-coverage-documentation/32-02-SUMMARY.md`
</output>
