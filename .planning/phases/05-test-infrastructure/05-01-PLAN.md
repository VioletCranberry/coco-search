---
phase: 05-test-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - tests/__init__.py
  - tests/conftest.py
  - tests/README.md
autonomous: true

must_haves:
  truths:
    - "pytest discovers tests in tests/ directory"
    - "pytest runs async tests with @pytest.mark.asyncio marker"
    - "pytest configuration uses strict asyncio mode"
  artifacts:
    - path: "pyproject.toml"
      provides: "pytest and pytest-asyncio configuration"
      contains: "asyncio_mode"
    - path: "tests/conftest.py"
      provides: "Root conftest with db pool reset fixture"
      min_lines: 15
    - path: "tests/README.md"
      provides: "Test conventions documentation"
      min_lines: 20
  key_links:
    - from: "pyproject.toml"
      to: "tests/"
      via: "testpaths configuration"
      pattern: 'testpaths.*tests'
---

<objective>
Configure pytest with async support for CocoSearch test infrastructure.

Purpose: Establish the foundation for all tests in Phases 5-6 with proper async handling and test conventions.
Output: Working pytest configuration, root conftest.py, and test conventions documentation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-test-infrastructure/05-CONTEXT.md
@.planning/phases/05-test-infrastructure/05-RESEARCH.md
@pyproject.toml
@src/cocosearch/search/db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install test dependencies and configure pytest</name>
  <files>pyproject.toml</files>
  <action>
Add pytest-asyncio, pytest-mock, and pytest-httpx to dev dependencies:
```bash
uv add --group dev pytest-asyncio pytest-mock pytest-httpx
```

Then add pytest configuration to pyproject.toml [tool.pytest.ini_options] section:
- testpaths = ["tests"]
- asyncio_mode = "strict" (explicit @pytest.mark.asyncio required per CONTEXT.md)
- asyncio_default_fixture_loop_scope = "function" (isolation per CONTEXT.md)
- python_files = ["test_*.py"]
- python_functions = ["test_*"]
- addopts = "-v --tb=short"
  </action>
  <verify>
Run: `uv run pytest --version` shows pytest installed
Run: `uv run python -c "import pytest_asyncio; print('ok')"` succeeds
  </verify>
  <done>
pyproject.toml contains [tool.pytest.ini_options] with asyncio_mode = "strict"
  </done>
</task>

<task type="auto">
  <name>Task 2: Create tests directory structure and conftest.py</name>
  <files>tests/__init__.py, tests/conftest.py</files>
  <action>
Create tests/ directory with:

1. tests/__init__.py - empty file to make tests a package

2. tests/conftest.py - root conftest with:
   - Docstring explaining this is the root conftest for cocosearch tests
   - Import pytest
   - pytest_plugins list (empty for now, will be populated by subsequent plans):
     ```python
     pytest_plugins = [
         # "tests.fixtures.db",      # Added by Plan 02
         # "tests.fixtures.ollama",  # Added by Plan 03
         # "tests.fixtures.data",    # Added by Plan 03
     ]
     ```
   - @pytest.fixture(autouse=True) reset_db_pool() that:
     - yields (allows test to run)
     - In teardown: imports cocosearch.search.db and sets db._pool = None
     - This prevents connection pool state leaking between tests (per RESEARCH.md pitfall 5)
   - @pytest.fixture tmp_codebase(tmp_path) that:
     - Creates a tmp_path / "codebase" directory
     - Creates a sample main.py file with simple function: `def hello():\n    return 'world'\n`
     - Creates a sample .gitignore with: `*.pyc\n__pycache__/\n`
     - Returns the codebase Path
  </action>
  <verify>
Run: `ls tests/conftest.py tests/__init__.py` shows both files exist
Run: `uv run python -c "from tests.conftest import tmp_codebase; print('ok')"` succeeds
  </verify>
  <done>
tests/conftest.py exists with reset_db_pool and tmp_codebase fixtures
  </done>
</task>

<task type="auto">
  <name>Task 3: Create test README and verify pytest discovery</name>
  <files>tests/README.md</files>
  <action>
Create tests/README.md documenting test conventions:

# CocoSearch Tests

## Running Tests

```bash
uv run pytest              # Run all tests
uv run pytest -v           # Verbose output
uv run pytest tests/test_search_query.py  # Run specific file
uv run pytest -k "search"  # Run tests matching pattern
```

## Conventions

- Test files: `test_*.py` in tests/ directory
- Test functions: `test_*`
- Async tests: Mark with `@pytest.mark.asyncio`
- Fixtures: Defined in tests/conftest.py or tests/fixtures/ modules

## Directory Structure

```
tests/
    conftest.py          # Root conftest, shared fixtures
    fixtures/            # Fixture modules (db, ollama, data)
    mocks/               # Mock classes (MockCursor, etc.)
    data/                # Test data files
    test_*.py            # Test modules
```

## Available Fixtures

### Built-in
- `tmp_codebase` - Temporary directory with sample Python files
- `reset_db_pool` (autouse) - Resets database pool between tests

### Database (tests.fixtures.db)
- `mock_db_pool` - Factory for mock database pool
- `patched_db_pool` - Auto-patched database pool

### Ollama (tests.fixtures.ollama)
- `mock_code_to_embedding` - Mock embedding function with deterministic output

## Mocking Philosophy

1. Mock at module boundaries, not library internals
2. Use deterministic mocks (same input = same output)
3. Track mock calls for assertions
4. Reset state between tests

Then create a minimal test to verify pytest discovery works:
Create tests/test_setup.py with:
```python
"""Verify pytest setup is working correctly."""

def test_pytest_works():
    """Simple test to verify pytest runs."""
    assert True

def test_tmp_codebase_fixture(tmp_codebase):
    """Verify tmp_codebase fixture works."""
    assert tmp_codebase.exists()
    assert (tmp_codebase / "main.py").exists()
```

Run pytest to verify discovery works.
  </action>
  <verify>
Run: `uv run pytest tests/test_setup.py -v` passes with 2 tests
Run: `uv run pytest --collect-only` shows test discovery working
  </verify>
  <done>
tests/README.md exists with conventions documented
pytest discovers and runs tests/test_setup.py successfully
  </done>
</task>

</tasks>

<verification>
All verification commands should pass:
```bash
# pytest installed and configured
uv run pytest --version

# Async support working
uv run python -c "import pytest_asyncio; print('pytest-asyncio ok')"

# Test discovery working
uv run pytest --collect-only

# Setup tests pass
uv run pytest tests/test_setup.py -v
```
</verification>

<success_criteria>
- pytest runs and discovers tests in tests/ directory
- pytest-asyncio installed with strict mode configured
- conftest.py has reset_db_pool (autouse) and tmp_codebase fixtures
- tests/README.md documents conventions
- tests/test_setup.py passes (verifies basic setup works)
</success_criteria>

<output>
After completion, create `.planning/phases/05-test-infrastructure/05-01-SUMMARY.md`
</output>
